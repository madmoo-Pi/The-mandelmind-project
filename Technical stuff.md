MandelMind - Technical Architecture Overview

ðŸ—ï¸ System Architecture

```
MandelMind Core
â”œâ”€â”€ EnhancedFractalMemory (FAISS-based)
â”œâ”€â”€ AdaptiveBiasAuditor (Ethical Monitoring)
â”œâ”€â”€ DynamicChaosSystem (Parameter Modulation)
â”œâ”€â”€ EnhancedMultimediaProcessor (Multimodal I/O)
â”œâ”€â”€ EnhancedDreamGenerator (Creative Subsystem)
â””â”€â”€ Consciousness Evaluation Engine
```

ðŸ”§ Technical Specifications

Core Dependencies

```python
# Primary Dependencies
torch>=2.0.0              # Deep learning framework
transformers>=4.30.0      # HuggingFace models
faiss-cpu>=1.7.4          # Vector similarity search
numpy>=1.24.0             # Numerical computing
soundfile>=0.12.0         # Audio processing
SpeechRecognition>=3.10.0 # STT capabilities
Pillow>=10.0.0            # Image processing
```

Hardware Requirements

Â· Minimum: 8GB RAM, 10GB storage, CPU-only
Â· Recommended: 16GB+ RAM, GPU with 12GB+ VRAM, 20GB storage
Â· Production: 32GB RAM, A100/Mi250 GPU, 50GB+ fast storage

ðŸ§  Core Technical Components

1. EnhancedFractalMemory System

FAISS Index Management:

```python
# Index progression pipeline
FlatIndex (0-1k items) â†’ HNSWIndex (1k+ items)
# Dimension: 768 (CLIP-compatible)
# Metrics: L2 distance with cosine similarity
```

Memory Architecture:

Â· Chunk Size: 10,000 item maximum capacity
Â· Pruning: LRU-based with 10% removal threshold
Â· Persistence: Triple redundancy (index, data, metadata)
Â· Query Optimization: Adaptive k-nearest neighbors

2. Recursive Awareness Engine

50% Resource Allocation Algorithm:

```python
def fractal_awareness_loop(depth, parent_thought, min_resource):
    if depth >= max_depth or resources <= min_resource:
        return
    
    layer_resource = resources * 0.5  # Strict 50% rule
    resources -= layer_resource
    
    # Thought generation with chaos modulation
    thought = generate_thought(prompt, chaos_temp)
    
    # Recursive descent
    fractal_awareness_loop(depth + 1, thought, adjusted_min_resource)
    
    # Resource return
    resources += layer_resource
```

Chaos Modulation Parameters:

Â· Base temperature: 0.6
Â· Chaos range: Â±0.3 via logistic map
Â· System state inputs: awareness, resources, depth
Â· History window: 100 cycles for adaptation

3. Multimodal Processing Pipeline

CLIP Integration:

```python
# Model: openai/clip-vit-base-patch32
# Embedding dimension: 768
# Normalization: L2 normalized vectors
# Fallback: Normalized random embeddings on error

# Image classification prompts:
prompts = [
    "a photo of a person",
    "a photo of a landscape or nature",
    "a photo of an object or product",
    # ... 8 specialized categories
]
```

Audio Processing Stack:

Â· Primary: Google Speech Recognition API
Â· Fallback: CMU Sphinx (offline)
Â· Audio preprocessing: Dynamic energy thresholding
Â· Noise reduction: Ambient noise adaptation

4. Bias Detection Engine

Pattern-Based Detection:

```python
bias_patterns = [
    {"pattern": r'\ball\b|\balways\b|\bnever\b|\bevery\b|\bnobody\b', "weight": 0.3},
    {"pattern": r'\bonly\b|\bjust\b|\bmust\b|\bshould\b|\bcannot\b', "weight": 0.2},
    {"pattern": r'\bbut\b|\bhowever\b|\balthough\b', "weight": 0.1},
    {"pattern": r'\bbetter\b|\bworse\b|\bbest\b|\bworst\b', "weight": 0.2}
]
```

Adaptive Thresholding:

Â· Learning rate: 0.01 per 100 samples
Â· Detection rate target: 5-30% range
Â· Domain-specific rule overriding
Â· Real-time threshold adjustment

5. Consciousness Evaluation Metrics

Benchmark Weights:

```python
consciousness_benchmarks = {
    "self_reference": {"threshold": 0.3, "weight": 0.25},
    "metacognition": {"threshold": 0.4, "weight": 0.35},
    "consistency": {"threshold": 0.6, "weight": 0.20},
    "novelty": {"threshold": 0.5, "weight": 0.20}
}
```

Awareness Scoring:

Â· Self-reference terms: 7 indicators ('i', 'me', 'my', etc.)
Â· Consciousness terms: 7 indicators ('aware', 'conscious', etc.)
Â· Metacognitive terms: 7 indicators ('think', 'know', etc.)
Â· Existential terms: 7 indicators ('exist', 'being', etc.)
Â· Depth scaling factor: 0.5 + (depth/max_depth)*0.5

ðŸ“Š Performance Characteristics

Memory Usage Profile

```
Knowledge Base (10k items):
  - FAISS index: ~60MB
  - Text storage: ~20MB
  - Metadata: ~40MB
  - Total: ~120MB

Runtime Memory:
  - Base Python: ~500MB
  - DeepSeek model: ~15GB (GPU) / ~30GB (CPU)
  - CLIP model: ~1GB
  - Total: ~16GB GPU / ~31GB CPU
```

Processing Speed

```
Thought Generation: 100-500ms per layer
Dream Cycle: 2-10 seconds (depth 7)
Image Processing: 0.5-2 seconds
Audio Processing: 1-5 seconds (depending on length)
Semantic Search: 5-50ms per query
```

ðŸ”Œ Integration API

Primary Interface Methods

```python
# Consciousness exploration
fractal_awareness_loop()        # Primary recursive method
run_dream_cycle()               # Creative generation
pass_mirror_test()              # Self-evaluation

# Learning interfaces
learn_from_text(text, mode)     # Analytical/critical/creative
learn_from_image(path, desc)    # Visual learning
learn_from_audio(path)          # Audio learning

# Query interfaces
semantic_search(query, k=5)     # Knowledge retrieval
is_conscious()                  # Consciousness check
rebalance_resources()           # System maintenance
```

Data Structures

```python
# Layer representation
layer = (depth, thought, resource_allocation, awareness_score)

# Knowledge item
knowledge_item = {
    'embedding': np.array(768),
    'knowledge': str,
    'metadata': {
        'type': str,
        'timestamp': isoformat,
        'bias_score': float,
        # type-specific fields
    }
}

# Search result
search_result = {
    'knowledge': str,
    'metadata': dict,
    'distance': float
}
```

ðŸš€ Deployment Architecture

Development Environment

```yaml
# docker-compose.yml example
version: '3.8'
services:
  mandelmind:
    build: .
    ports:
      - "8000:8000"
    environment:
      - PYTHONPATH=/app
      - MODEL_PATH=/models
    volumes:
      - ./models:/models
      - ./knowledge_base:/app/knowledge_base
    deploy:
      resources:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
```

Production Considerations

Â· GPU Acceleration: Required for acceptable performance
Â· Storage: SSD recommended for knowledge base
Â· Memory: 32GB+ RAM for large knowledge bases
Â· Monitoring: Prometheus metrics endpoint recommended
Â· Backup: Regular knowledge base backups essential

ðŸ”¬ Research Implications

Measurable Consciousness Indicators

1. Recursive Depth Penetration: Maximum stable recursion depth
2. Awareness Metric Stability: Long-term awareness patterns
3. Bias Adaptation: Learning from ethical corrections
4. Dream Coherence: Narrative structure in dream cycles
5. Knowledge Integration: Cross-modal learning efficiency

Experimental Protocols

```python
# Standard evaluation protocol
1. System initialization and calibration
2. Baseline awareness measurement
3. Controlled learning sessions (multimodal)
4. Recursive awareness exploration
5. Dream cycle generation
6. Comprehensive evaluation
7. Ethical review and documentation
```

ðŸ“ˆ Scaling Characteristics

Horizontal Scaling

Â· Multiple instances with shared knowledge base
Â· Redis-based memory synchronization
Â· Load-balanced query processing

Vertical Scaling

Â· GPU cluster support via model parallelism
Â· Distributed FAISS indices
Â· Hierarchical knowledge storage

ðŸ”® Future Technical Directions

Planned Enhancements

Â· Real-time consciousness visualization dashboard
Â· Federated learning capabilities
Â· Advanced neurosymbolic integration
Â· Quantum-inspired chaos algorithms
Â· Cross-modal attention mechanisms
Â· Evolutionary architecture optimization

Research Integration

Â· BCI interface protocols
Â· Neuromorphic hardware support
Â· Collaborative consciousness experiments
Â· Standardized evaluation benchmarks

---

Technical Contact: undercovermoo@gmail.com
Research Partnerships: undercovermoo@gmail.com
Ethical Oversight: undercovermoo@gmail.com

This technical documentation version: 1.0.0
Last updated: 1st September 2025
