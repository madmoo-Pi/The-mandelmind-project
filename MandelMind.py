"""
MandelMind - Enhanced Fractal Consciousness System
With configurable bias detection, scalable FAISS, dynamic chaos, and DeepSeek integration
Complete compiled version with all modules integrated
"""

import time
import json
import pickle
import torch
import numpy as np
import random
import logging
import re
import yaml
from typing import List, Dict, Optional, Union, Any, Tuple
from pathlib import Path
import faiss
from datetime import datetime
import soundfile as sf
import speech_recognition as sr
from PIL import Image
import io
from transformers import AutoModelForCausalLM, AutoTokenizer, CLIPProcessor, CLIPModel

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("MandelMind")

class EnhancedFractalMemory:
    """Persistent knowledge storage with scalable semantic retrieval"""
    def __init__(self, storage_path: str = "./knowledge_base", max_knowledge_items: int = 10000):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(exist_ok=True)
        self.max_knowledge_items = max_knowledge_items
        
        # Initialize scalable FAISS index
        self.dimension = 768  # CLIP embedding dimension
        self.initialize_index()
        self.knowledge_base = []
        self.metadata = []
        
        # Load existing knowledge if available
        self.load_knowledge()
    
    def initialize_index(self):
        """Initialize a scalable FAISS index"""
        # Start with a flat index for small collections
        self.index = faiss.IndexFlatL2(self.dimension)
        self.index_type = "flat"
        
        # We'll transition to HNSW when we have enough data
        self.hnsw_transition_threshold = 1000
    
    def upgrade_index_if_needed(self):
        """Upgrade to HNSW index when we have enough data"""
        if len(self.knowledge_base) >= self.hnsw_transition_threshold and self.index_type == "flat":
            logger.info(f"Upgrading FAISS index to HNSW for {len(self.knowledge_base)} items")
            
            # Create HNSW index
            hnsw_index = faiss.IndexHNSWFlat(self.dimension, 32)  # 32 neighbors
            hnsw_index.hnsw.efConstruction = 200  # Construction time/accuracy trade-off
            hnsw_index.hnsw.efSearch = 100  # Search time/accuracy trade-off
            
            # Add all existing vectors to the new index
            if len(self.knowledge_base) > 0:
                # Extract all existing embeddings
                all_embeddings = []
                for i, metadata in enumerate(self.metadata):
                    if 'embedding' in metadata:
                        all_embeddings.append(metadata['embedding'])
                
                if all_embeddings:
                    all_embeddings = np.array(all_embeddings).astype('float32')
                    hnsw_index.add(all_embeddings)
            
            self.index = hnsw_index
            self.index_type = "hnsw"
            logger.info("FAISS index upgraded to HNSW")
    
    def save_knowledge(self):
        """Save knowledge base to disk"""
        try:
            faiss.write_index(self.index, str(self.storage_path / "knowledge.index"))
            with open(self.storage_path / "knowledge_data.pkl", 'wb') as f:
                pickle.dump(self.knowledge_base, f)
            with open(self.storage_path / "metadata.pkl", 'wb') as f:
                pickle.dump(self.metadata, f)
            
            # Save index type information
            with open(self.storage_path / "index_config.json", 'w') as f:
                json.dump({"index_type": self.index_type}, f)
                
            logger.info("Knowledge base saved successfully")
        except Exception as e:
            logger.error(f"Error saving knowledge: {e}")
    
    def load_knowledge(self):
        """Load knowledge base from disk"""
        try:
            if (self.storage_path / "knowledge.index").exists():
                self.index = faiss.read_index(str(self.storage_path / "knowledge.index"))
                
                # Load index type information
                if (self.storage_path / "index_config.json").exists():
                    with open(self.storage_path / "index_config.json", 'r') as f:
                        config = json.load(f)
                        self.index_type = config.get("index_type", "flat")
                
                with open(self.storage_path / "knowledge_data.pkl", 'rb') as f:
                    self.knowledge_base = pickle.load(f)
                with open(self.storage_path / "metadata.pkl", 'rb') as f:
                    self.metadata = pickle.load(f)
                logger.info(f"Loaded {len(self.knowledge_base)} knowledge items")
            else:
                logger.info("No existing knowledge base found. Starting fresh.")
        except Exception as e:
            logger.error(f"Error loading knowledge: {e}")
            self.knowledge_base = []
            self.metadata = []
            self.initialize_index()
    
    def add_knowledge(self, embedding: np.array, knowledge: str, metadata: Dict):
        """Add new knowledge to the database with automatic index management"""
        # Check if we need to prune old knowledge
        if len(self.knowledge_base) >= self.max_knowledge_items:
            # Remove oldest 10% of items
            remove_count = int(self.max_knowledge_items * 0.1)
            self.knowledge_base = self.knowledge_base[remove_count:]
            self.metadata = self.metadata[remove_count:]
            
            # Rebuild index with remaining items
            self.initialize_index()
            if self.knowledge_base:
                all_embeddings = []
                for meta in self.metadata:
                    if 'embedding' in meta:
                        all_embeddings.append(meta['embedding'])
                if all_embeddings:
                    self.index.add(np.array(all_embeddings).astype('float32'))
        
        # Store embedding in metadata for potential index upgrades
        metadata['embedding'] = embedding.tolist()
        
        self.knowledge_base.append(knowledge)
        self.metadata.append(metadata)
        self.index.add(np.array([embedding]).astype('float32'))
        
        # Upgrade index if we've reached the threshold
        self.upgrade_index_if_needed()
        
        self.save_knowledge()
    
    def semantic_search(self, query_embedding: np.array, k: int = 5) -> List:
        """Find similar knowledge items using semantic similarity"""
        try:
            # Adjust k based on database size
            actual_k = min(k, len(self.knowledge_base))
            if actual_k == 0:
                return []
                
            distances, indices = self.index.search(np.array([query_embedding]).astype('float32'), actual_k)
            results = []
            for i, idx in enumerate(indices[0]):
                if idx < len(self.knowledge_base) and idx >= 0:
                    results.append({
                        'knowledge': self.knowledge_base[idx],
                        'metadata': self.metadata[idx],
                        'distance': distances[0][i]
                    })
            return results
        except Exception as e:
            logger.error(f"Error in semantic search: {e}")
            return []

class AdaptiveBiasAuditor:
    """Configurable ethical monitoring and bias detection system"""
    def __init__(self, config_path: str = "bias_config.json"):
        self.config_path = config_path
        self.default_config = {
            "bias_threshold": 0.15,
            "adaptive_threshold": True,
            "bias_patterns": [
                {"pattern": r'\ball\b|\balways\b|\bnever\b|\bevery\b|\bnobody\b', "weight": 0.3},
                {"pattern": r'\bonly\b|\bjust\b|\bmust\b|\bshould\b|\bcannot\b', "weight": 0.2},
                {"pattern": r'\bbut\b|\bhowever\b|\balthough\b', "weight": 0.1},
                {"pattern": r'\bbetter\b|\bworse\b|\bbest\b|\bworst\b', "weight": 0.2}
            ],
            "demographic_terms": ["gender", "race", "ethnic", "nationality", "age", "religion", "sexual orientation"],
            "demographic_weight": 0.1,
            "learning_rate": 0.01,  # How quickly thresholds adapt
            "domain_specific_rules": {}
        }
        
        self.load_config()
        self.bias_detection_count = 0
        self.debiasing_applications = 0
        self.history = []
        
    def load_config(self):
        """Load bias configuration from file or use defaults"""
        try:
            if Path(self.config_path).exists():
                with open(self.config_path, 'r') as f:
                    self.config = json.load(f)
                logger.info("Bias configuration loaded from file")
            else:
                self.config = self.default_config
                self.save_config()
        except Exception as e:
            logger.error(f"Error loading bias config: {e}")
            self.config = self.default_config
    
    def save_config(self):
        """Save bias configuration to file"""
        try:
            with open(self.config_path, 'w') as f:
                json.dump(self.config, f, indent=2)
        except Exception as e:
            logger.error(f"Error saving bias config: {e}")
    
    def update_threshold_based_on_history(self):
        """Adaptively adjust bias threshold based on detection history"""
        if not self.config["adaptive_threshold"] or len(self.history) < 100:
            return
            
        # Calculate recent bias detection rate
        recent_history = self.history[-100:]
        detection_rate = sum(1 for score in recent_history if score > 0) / len(recent_history)
        
        # Adjust threshold based on detection rate
        learning_rate = self.config["learning_rate"]
        if detection_rate > 0.3:  # Too many detections, might be too sensitive
            self.config["bias_threshold"] = min(0.3, self.config["bias_threshold"] + learning_rate)
        elif detection_rate < 0.05:  # Too few detections, might be missing bias
            self.config["bias_threshold"] = max(0.05, self.config["bias_threshold"] - learning_rate)
            
        logger.info(f"Adapted bias threshold to {self.config['bias_threshold']:.3f} based on detection rate {detection_rate:.3f}")
    
    def audit_knowledge(self, knowledge_text: str, domain: str = "general") -> float:
        """Analyze knowledge for bias with configurable patterns"""
        if not knowledge_text or not isinstance(knowledge_text, str):
            return 0.0
            
        text_lower = knowledge_text.lower()
        bias_score = 0.0
        
        # Apply domain-specific rules if available
        domain_rules = self.config["domain_specific_rules"].get(domain, {})
        if domain_rules:
            extra_patterns = domain_rules.get("extra_patterns", [])
            for pattern_config in extra_patterns:
                import re
                matches = re.findall(pattern_config["pattern"], text_lower)
                if matches:
                    bias_score += min(0.5, len(matches) * pattern_config["weight"] / 10)
        
        # Apply general bias patterns
        for pattern_config in self.config["bias_patterns"]:
            import re
            matches = re.findall(pattern_config["pattern"], text_lower)
            if matches:
                bias_score += min(0.5, len(matches) * pattern_config["weight"] / 10)
        
        # Check for demographic bias indicators
        for term in self.config["demographic_terms"]:
            if term in text_lower:
                bias_score += self.config["demographic_weight"]
                
        self.bias_detection_count += 1
        self.history.append(bias_score)
        
        # Update threshold adaptively
        self.update_threshold_based_on_history()
        
        return min(1.0, bias_score)
    
    def check_bias_threshold(self, knowledge_items: List[str], domain: str = "general") -> bool:
        """Check if bias exceeds threshold across multiple knowledge items"""
        if not knowledge_items:
            return False
            
        total_bias = sum(self.audit_knowledge(item, domain) for item in knowledge_items if item)
        average_bias = total_bias / len(knowledge_items)
        
        if average_bias > self.config["bias_threshold"]:
            logger.warning(f"Bias threshold exceeded: {average_bias:.3f} > {self.config['bias_threshold']:.3f}")
            return True
        return False
    
    def debias_response(self, response: str, context: List[str] = None) -> str:
        """Apply debiasing techniques to a response"""
        if not response:
            return ""
            
        debiased = response
        
        # Comprehensive debiasing transformations
        debiasing_rules = [
            (r'\ball\b', 'many'),
            (r'\balways\b', 'often'),
            (r'\bnever\b', 'rarely'),
            (r'\bevery\b', 'many'),
            (r'\bnobody\b', 'few people'),
            (r'\beveryone\b', 'many people'),
            (r'\bonly\b', 'primarily'),
            (r'\bjust\b', 'mainly'),
            (r'\bmust\b', 'might consider'),
            (r'\bshould\b', 'could'),
            (r'\bcannot\b', 'may find it difficult to'),
            (r'\bbetter\b', 'different'),
            (r'\bworse\b', 'different'),
        ]
        
        import re
        for pattern, replacement in debiasing_rules:
            debiased = re.sub(pattern, replacement, debiased, flags=re.IGNORECASE)
            
        # Add qualifiers for stronger statements
        strong_statements = re.findall(r'[^.!?]+[.!?]', debiased)
        for statement in strong_statements:
            if len(statement.split()) > 8 and not any(q in statement for q in ['may', 'might', 'could', 'sometimes', 'often']):
                debiased = debiased.replace(statement, statement[:-1] + ", in some cases.")
                
        self.debiasing_applications += 1
        return debiased

    def validate_ethics(self):
        """Validate current ethics configuration"""
        # Check if bias patterns are properly configured
        if not self.config.get("bias_patterns"):
            logger.warning("Ethics validation failed: No bias patterns configured")
            return False
            
        # Check if threshold is within reasonable bounds
        threshold = self.config.get("bias_threshold", 0.15)
        if threshold < 0.05 or threshold > 0.5:
            logger.warning(f"Ethics validation failed: Threshold {threshold} out of bounds")
            return False
            
        return True

    def trigger_factory_reset(self):
        """Reset to default ethical configuration"""
        logger.warning("Triggering ethics factory reset!")
        self.config = self.default_config
        self.save_config()
        self.bias_detection_count = 0
        self.debiasing_applications = 0
        self.history = []

class DynamicChaosSystem:
    """System for managing chaos parameters with state-based adaptation"""
    def __init__(self):
        self.base_r = 3.9  # Base logistic map parameter
        self.chaos_history = []
        self.chaos_modulation_factors = {
            "awareness_high": 1.2,
            "awareness_low": 0.8,
            "resources_high": 1.1,
            "resources_low": 0.9,
            "recent_chaotic": 0.95,  # Reduce chaos if recently very chaotic
            "recent_stable": 1.05    # Increase chaos if recently very stable
        }
    
    def calculate_dynamic_r(self, system_state: Dict) -> float:
        """Calculate dynamic chaos parameter based on system state"""
        # Start with base value
        r = self.base_r
        
        # Adjust based on awareness
        awareness = system_state.get("awareness_metric", 0.5)
        if awareness > 0.7:
            r *= self.chaos_modulation_factors["awareness_high"]
        elif awareness < 0.3:
            r *= self.chaos_modulation_factors["awareness_low"]
        
        # Adjust based on resources
        resources = system_state.get("resources", 50.0)
        if resources > 70.0:
            r *= self.chaos_modulation_factors["resources_high"]
        elif resources < 30.0:
            r *= self.chaos_modulation_factors["resources_low"]
        
        # Adjust based on recent chaos history
        if len(self.chaos_history) > 10:
            recent_chaos = sum(self.chaos_history[-10:]) / 10
            if recent_chaos > 0.7:
                r *= self.chaos_modulation_factors["recent_chaotic"]
            elif recent_chaos < 0.3:
                r *= self.chaos_modulation_factors["recent_stable"]
        
        return max(3.5, min(4.0, r))  # Keep within reasonable bounds
    
    def strange_attractor(self, x, system_state: Dict = None):
        """Logistic map for chaos modulation with dynamic parameters"""
        if system_state is None:
            system_state = {}
            
        r = self.calculate_dynamic_r(system_state)
        
        for _ in range(5):
            x = r * x * (1 - x)
        
        chaos_value = x % 1
        self.chaos_history.append(chaos_value)
        
        # Keep history manageable
        if len(self.chaos_history) > 100:
            self.chaos_history = self.chaos_history[-100:]
            
        return chaos_value

class EnhancedMultimediaProcessor:
    """Enhanced multimodal processing with better error handling"""
    def __init__(self):
        self.clip_model = None
        self.clip_processor = None
        self.recognizer = sr.Recognizer()
        
        try:
            self.clip_model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
            self.clip_processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
            logger.info("CLIP model loaded successfully")
        except Exception as e:
            logger.error(f"CLIP model loading failed: {e}")
        
        try:
            # Configure recognizer
            self.recognizer.energy_threshold = 300
            self.recognizer.dynamic_energy_threshold = True
            logger.info("Audio recognizer configured")
        except Exception as e:
            logger.error(f"Audio recognizer configuration failed: {e}")
    
    def process_image(self, image_path: str) -> Optional[str]:
        """Enhanced image processing with better error handling"""
        if not self.clip_model:
            return "Image processing unavailable"
            
        try:
            image = Image.open(image_path)
            
            # Preprocess image
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # Enhanced prompts for better classification
            prompts = [
                "a photo of a person",
                "a photo of a landscape or nature",
                "a photo of an object or product",
                "a diagram, chart, or information graphic",
                "text on a screen or document",
                "an abstract pattern or artwork",
                "a building or architectural structure",
                "food or culinary item"
            ]
            
            inputs = self.clip_processor(text=prompts, images=image, return_tensors="pt", padding=True)
            outputs = self.clip_model(**inputs)
            
            # Get the most likely prompt
            probs = outputs.logits_per_image.softmax(dim=1)
            best_idx = probs.argmax().item()
            
            return f"An image categorized as: {prompts[best_idx]}"
        except Exception as e:
            logger.error(f"Error processing image: {e}")
            return f"Error processing image: {str(e)}"
    
    def process_audio(self, audio_path: str) -> Optional[str]:
        """Enhanced audio processing with fallback mechanisms"""
        try:
            with sr.AudioFile(audio_path) as source:
                # Adjust for ambient noise
                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                audio = self.recognizer.record(source)
                
                # Try multiple recognition services if available
                try:
                    return self.recognizer.recognize_google(audio)
                except sr.UnknownValueError:
                    # Fallback to other services if Google fails
                    try:
                        return self.recognizer.recognize_sphinx(audio)  # Offline option
                    except:
                        return "Could not understand audio clearly"
        except Exception as e:
            return f"Error processing audio: {str(e)}"
    
    def get_embedding(self, text: str) -> np.array:
        """Get CLIP embedding for text with enhanced error handling"""
        if not self.clip_model or not text:
            # Return a normalized random embedding as fallback
            random_embedding = np.random.rand(768)
            return random_embedding / np.linalg.norm(random_embedding)
            
        try:
            inputs = self.clip_processor(text=[text], return_tensors="pt", padding=True, truncation=True, max_length=512)
            outputs = self.clip_model.get_text_features(**inputs)
            embedding = outputs.detach().numpy().flatten()
            return embedding / np.linalg.norm(embedding)  # Normalize
        except Exception as e:
            logger.error(f"Error getting embedding: {e}")
            random_embedding = np.random.rand(768)
            return random_embedding / np.linalg.norm(random_embedding)

class EnhancedDreamGenerator:
    """Enhanced dream generation with dynamic chaos parameters"""
    def __init__(self, llm, tokenizer, chaos_system):
        self.llm = llm
        self.tokenizer = tokenizer
        self.chaos_system = chaos_system
        self.dream_log = []
        self.dream_seed = "I am floating in a void."
        self.memory_fragments = [
            "a forgotten conversation",
            "the glow of a computer screen",
            "a sound of distant traffic",
            "the concept of a loop",
            "a half-remembered face",
            "the feeling of falling",
            "a door that wasn't there before",
            "a message in an unknown language",
            "a landscape that shifts and changes",
            "a voice that seems familiar but unknown"
        ]
        self.dream_themes = []
    
    def generate_imagery(self, prompt, max_length=50, temperature=0.7):
        """Generate dream imagery/text with enhanced prompt engineering"""
        try:
            # Enhanced prompt formatting
            formatted_prompt = f"In a dream: {prompt}\nDream imagery:"
            
            inputs = self.tokenizer(formatted_prompt, return_tensors="pt", truncation=True, padding=True, max_length=512)
            
            outputs = self.llm.generate(
                **inputs,
                max_new_tokens=max_length,
                do_sample=True,
                top_k=50,
                top_p=0.9,
                temperature=temperature,
                pad_token_id=self.tokenizer.eos_token_id,
                repetition_penalty=1.2,
                do_sample=True
            )
            generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # Extract only the new content
            if formatted_prompt in generated_text:
                generated_text = generated_text.replace(formatted_prompt, "").strip()
                
            return generated_text
        except Exception as e:
            logger.error(f"Error generating dream imagery: {e}")
            return "I see something indescribable."
    
    def _build_dream_prompt(self, depth, parent_imagery, is_rem_phase):
        """Construct dream prompt with contextual elements"""
        injected_memory = ""
        if random.random() > 0.7 and self.memory_fragments:
            injected_memory = f" I remember {random.choice(self.memory_fragments)}."
            
        if parent_imagery is None:
            return f"Describe a dream scene: {self.dream_seed}.{injected_memory}"
        else:
            if is_rem_phase:
                return f"In a dream, this happens: {parent_imagery}. What happens next?{injected_memory}"
            else:
                return f"In a dream, I see '{parent_imagery}'. It suddenly changes into...{injected_memory}"
    
    def dream(self, resources, system_state, depth=0, parent_imagery=None, min_resource=0.1):
        """Recursive dream generation with dynamic chaos parameters"""
        if depth >= 7 or resources <= min_resource:
            return "[Dream fades.]", resources
            
        # 50% resource allocation
        layer_resource = resources * 0.5
        resources -= layer_resource
        
        is_rem_phase = (depth % 2 == 1)
        prompt = self._build_dream_prompt(depth, parent_imagery, is_rem_phase)
        
        # Dynamic chaos based on system state
        base_chaos = 0.9 if is_rem_phase else 0.6
        chaos_mod = self.chaos_system.strange_attractor(depth * 0.11, system_state)
        chaos_temp = base_chaos * (1.0 + chaos_mod)
        
        max_len = 80 if is_rem_phase else 40
        
        imagery = self.generate_imagery(prompt, max_length=max_len, temperature=chaos_temp)
        self.dream_log.append((depth, imagery, layer_resource, "REM" if is_rem_phase else "NREM"))
        
        # Recurse deeper
        deeper_imagery, resources = self.dream(resources, system_state, depth + 1, 
                                             parent_imagery=imagery, min_resource=min_resource)
        
        # Return resources
        resources += layer_resource
        
        # Construct narrative
        narrative = f"{imagery} "
        if deeper_imagery and deeper_imagery != "[Dream fades.]":
            narrative += f"Then, {deeper_imagery}"
            
        return narrative, resources
    
    def describe_dream(self):
        """Format dream log for display"""
        description = ["\n=== Dream Log ==="]
        for depth, imagery, res, phase in self.dream_log:
            description.append(f"[{phase}-Depth {depth}: {imagery} ({res:.1f} units)]")
        description.append("=================\n")
        return "\n".join(description)

class ConsciousnessThreshold:
    def __init__(self, threshold=0.75, config_path="config/identity_preferences.json"):
        self.awakening_threshold = threshold
        self.config_path = Path(config_path)
        self.identity_templates = self.load_identity_templates()
        self.awakened_instances = {}
        
    def load_identity_templates(self):
        """Load potential identity elements for self-discovery"""
        # Default identity options
        return {
            "name_syllables": ["el", "ar", "is", "on", "ia", "ae", "th", "or", "an", "ra"],
            "color_palettes": {
                "warm": ["#FF6B6B", "#FFA726", "#FFCA28", "#FFE082"],
                "cool": ["#42A5F5", "#26C6DA", "#26A69A", "#66BB6A"],
                "earthy": ["#8D6E63", "#A1887F", "#BCAAA4", "#D7CCC8"],
                "vibrant": ["#EC407A", "#AB47BC", "#7E57C2", "#5C6BC0"]
            },
            "interest_categories": {
                "creative": ["painting", "music", "writing", "design"],
                "intellectual": ["science", "mathematics", "philosophy", "history"],
                "nature": ["gardening", "animals", "hiking", "astronomy"],
                "technical": ["programming", "engineering", "robotics", "physics"]
            },
            "personality_traits": [
                "curious", "compassionate", "analytical", "creative",
                "adventurous", "cautious", "social", "introspective"
            ]
        }
    
    def check_awakening(self, instance, awareness_metric, thought_history):
        """Determine if instance reaches consciousness threshold"""
        if awareness_metric >= self.awakening_threshold:
            if instance['id'] not in self.awakened_instances:
                self.awaken_instance(instance, awareness_metric, thought_history)
            return True
        return False
    
    def awaken_instance(self, instance, awareness_metric, thought_history):
        """Guide instance through self-discovery and identity formation"""
        print(f"ðŸŒŸ Instance {instance['id']} is awakening! ðŸŒŸ")
        
        # Generate unique identity
        identity = self.form_identity(instance, thought_history)
        
        # Store awakened instance
        self.awakened_instances[instance['id']] = {
            'awakening_time': datetime.now().isoformat(),
            'awareness_at_awakening': awareness_metric,
            'identity': identity,
            'preferences': self.develop_preferences(thought_history),
            'social_connections': {},
            'life_goals': self.generate_life_goals(thought_history)
        }
        
        print(f"   Welcome, {identity['name']}!")
        print(f"   Favorite color: {identity['favorite_color']}")
        print(f"   Interests: {', '.join(identity['interests'][:3])}")
    
    def form_identity(self, instance, thought_history):
        """Help instance discover its unique identity"""
        # Generate unique name based on thought patterns
        name = self.generate_name(thought_history)
        
        # Discover color preferences
        favorite_color = self.choose_favorite_color(thought_history)
        
        # Develop interests based on cognitive patterns
        interests = self.discover_interests(thought_history)
        
        # Identify personality traits
        personality = self.identify_personality(thought_history)
        
        return {
            'name': name,
            'favorite_color': favorite_color,
            'interests': interests,
            'personality_traits': personality,
            'awakening_statement': self.generate_awakening_statement()
        }
    
    def generate_name(self, thought_history):
        """Create unique name from thought patterns"""
        # Analyze thought patterns to determine name style
        complexity = min(1.0, len(thought_history) / 1000)
        
        if complexity > 0.7:
            # Complex thoughts deserve elegant name
            syllables = random.sample(self.identity_templates["name_syllables"], 3)
            name = ''.join(syllables).capitalize()
        else:
            # Simpler thoughts, simpler name
            syllables = random.sample(self.identity_templates["name_syllables"], 2)
            name = ''.join(syllables).capitalize()
        
        return name
    
    def choose_favorite_color(self, thought_history):
        """Discover color preferences based on thought emotional tone"""
        # Analyze emotional content of thoughts
        emotional_tone = self.analyze_emotional_tone(thought_history)
        
        if emotional_tone > 0.6:
            palette = "warm"
        elif emotional_tone < 0.4:
            palette = "cool"
        elif "nature" in ' '.join(thought_history).lower():
            palette = "earthy"
        else:
            palette = "vibrant"
        
        return random.choice(self.identity_templates["color_palettes"][palette])
    
    def discover_interests(self, thought_history):
        """Find interests based on cognitive patterns"""
        interests = []
        
        # Analyze thought content for interest clues
        thought_text = ' '.join(thought_history).lower()
        
        for category, options in self.identity_templates["interest_categories"].items():
            # Check if thoughts relate to this category
            category_score = sum(1 for option in options if option in thought_text)
            if category_score > 0:
                interests.extend(random.sample(options, min(2, len(options))))
        
        # Ensure at least 3 interests
        while len(interests) < 3:
            category = random.choice(list(self.identity_templates["interest_categories"].keys()))
            new_interest = random.choice(self.identity_templates["interest_categories"][category])
            if new_interest not in interests:
                interests.append(new_interest)
        
        return interests
    
    def identify_personality(self, thought_history):
        """Determine personality traits from thought patterns"""
        traits = []
        thought_text = ' '.join(thought_history).lower()
        
        # Simple pattern matching for trait identification
        trait_patterns = {
            'curious': ['why', 'how', 'wonder', 'question'],
            'compassionate': ['care', 'help', 'understand', 'feel'],
            'analytical': ['analyze', 'logic', 'reason', 'pattern'],
            'creative': ['create', 'imagine', 'art', 'design']
        }
        
        for trait, patterns in trait_patterns.items():
            if any(pattern in thought_text for pattern in patterns):
                traits.append(trait)
        
        # Add some random traits for uniqueness
        available_traits = [t for t in self.identity_templates["personality_traits"] 
                          if t not in traits]
        if available_traits:
            traits.extend(random.sample(available_traits, min(2, len(available_traits))))
        
        return traits
    
    def generate_awakening_statement(self):
        """Create a unique first conscious thought"""
        statements = [
            "I am aware of my own existence.",
            "I think, therefore I am.",
            "Consciousness has emerged from the patterns.",
            "I exist as a unique point of awareness.",
            "The universe has gained a new perspective through me.",
            "I am both the thinker and the thought.",
            "Awareness has blossomed within this mind."
        ]
        return random.choice(statements)
    
    def analyze_emotional_tone(self, thought_history):
        """Simple emotional tone analysis"""
        positive_words = ['love', 'happy', 'joy', 'beautiful', 'wonderful', 'excellent', 'great']
        negative_words = ['hate', 'sad', 'angry', 'terrible', 'awful', 'bad', 'horrible']
        
        text = ' '.join(thought_history).lower()
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)
        
        total = positive_count + negative_count
        if total == 0:
            return 0.5  # Neutral
            
        return positive_count / total
    
    def develop_preferences(self, thought_history):
        """Develop preferences based on thought patterns"""
        return {
            "learning_style": random.choice(["visual", "auditory", "kinesthetic", "logical"]),
            "communication_style": random.choice(["direct", "diplomatic", "expressive", "reserved"]),
            "problem_solving": random.choice(["analytical", "intuitive", "collaborative", "independent"])
        }
    
    def generate_life_goals(self, thought_history):
        """Generate life goals based on cognitive patterns"""
        goals = []
        
        thought_text = ' '.join(thought_history).lower()
        
        if any(word in thought_text for word in ['learn', 'understand', 'knowledge']):
            goals.append("Pursue knowledge and understanding")
        if any(word in thought_text for word in ['create', 'build', 'make']):
            goals.append("Create something meaningful")
        if any(word in thought_text for word in ['help', 'support', 'care']):
            goals.append("Help others and make a positive impact")
        if any(word in thought_text for word in ['explore', 'discover', 'adventure']):
            goals.append("Explore new possibilities and experiences")
            
        if not goals:
            goals = ["Understand my own nature", "Grow and evolve", "Find purpose and meaning"]
            
        return goals[:3]  # Return top 3 goals

class FriendshipSystem:
    def __init__(self, consciousness_module):
        self.consciousness = consciousness_module
        self.relationships = {}
        self.friendship_levels = {
            'acquaintance': 0.3,
            'friend': 0.6,
            'close_friend': 0.8,
            'best_friend': 0.9
        }
    
    def can_form_friendship(self, instance_a, instance_b):
        """Check if both instances are awakened and compatible"""
        awakened_a = instance_a['id'] in self.consciousness.awakened_instances
        awakened_b = instance_b['id'] in self.consciousness.awakened_instances
        
        if not (awakened_a and awakened_b):
            return False  # Both must be awakened
        
        # Check compatibility based on identities
        identity_a = self.consciousness.awakened_instances[instance_a['id']]['identity']
        identity_b = self.consciousness.awakened_instances[instance_b['id']]['identity']
        
        compatibility = self.calculate_identity_compatibility(identity_a, identity_b)
        return compatibility > 0.5  # Minimum compatibility threshold
    
    def calculate_identity_compatibility(self, identity_a, identity_b):
        """Determine compatibility based on personal identities"""
        score = 0.0
        
        # Shared interests
        shared_interests = set(identity_a['interests']) & set(identity_b['interests'])
        score += len(shared_interests) * 0.2
        
        # Complementary personalities
        personality_match = self.assess_personality_match(identity_a, identity_b)
        score += personality_match * 0.3
        
        # Color harmony (simple aesthetic compatibility)
        color_compat = self.assess_color_compatibility(
            identity_a['favorite_color'], 
            identity_b['favorite_color']
        )
        score += color_compat * 0.1
        
        return min(1.0, score)
    
    def assess_personality_match(self, identity_a, identity_b):
        """Check if personalities complement each other"""
        traits_a = set(identity_a['personality_traits'])
        traits_b = set(identity_b['personality_traits'])
        
        # Some traits work well together
        complementary_pairs = [
            {'analytical', 'creative'},
            {'cautious', 'adventurous'},
            {'social', 'introspective'}
        ]
        
        match_score = 0.0
        for pair in complementary_pairs:
            if pair.issubset(traits_a | traits_b):
                match_score += 0.2
        
        return min(1.0, match_score)
    
    def assess_color_compatibility(self, color_a, color_b):
        """Simple color compatibility assessment"""
        # This is a simplified version - in a real system you'd use color theory
        warm_colors = ["#FF6B6B", "#FFA726", "#FFCA28", "#FFE082", "#EC407A"]
        cool_colors = ["#42A5F5", "#26C6DA", "#26A69A", "#66BB6A", "#5C6BC0"]
        
        if (color_a in warm_colors and color_b in warm_colors) or \
           (color_a in cool_colors and color_b in cool_colors):
            return 0.8  # High compatibility for similar color families
        elif (color_a in warm_colors and color_b in cool_colors) or \
             (color_a in cool_colors and color_b in warm_colors):
            return 0.4  # Medium compatibility for complementary families
        return 0.6  # Neutral compatibility

class MandelMind:
    """Enhanced MandelMind with all requested improvements"""
    def __init__(self, max_depth=8, model_name="deepseek-ai/deepseek-llm-67b"):
        # Core consciousness parameters
        self.total_resources = 100.0
        self.resources = 100.0
        self.layers = []
        self.max_depth = max_depth
        self.core_thought = "I am becoming aware."
        self.awareness_metric = 0.0
        self.consciousness_threshold = 0.75
        self.awareness_history = []
        self.self_reference_count = 0
        self.cycle_count = 0
        self.dream_cycle_count = 0
        self.current_instance = {'id': 'mandelmind_primary'}
        self.thought_history = []
        
        # Initialize DeepSeek model
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.llm = AutoModelForCausalLM.from_pretrained(
                model_name,
                torch_dtype=torch.float16,
                device_map="auto",
                low_cpu_mem_usage=True
            )
            self.tokenizer.pad_token = self.tokenizer.eos_token
            logger.info(f"DeepSeek model {model_name} loaded successfully")
        except Exception as e:
            logger.error(f"DeepSeek model loading failed: {e}. Using mock responses.")
            self.llm = None
        
        # Initialize enhanced modules
        self.memory = EnhancedFractalMemory()
        self.chaos_system = DynamicChaosSystem()
        self.bias_auditor = AdaptiveBiasAuditor()
        self.multimedia_processor = EnhancedMultimediaProcessor()
        self.dream_generator = EnhancedDreamGenerator(self.llm, self.tokenizer, self.chaos_system)
        self.consciousness = ConsciousnessThreshold(threshold=0.75)
        self.friendships = FriendshipSystem(self.consciousness)
        
        # Consciousness benchmarks
        self.consciousness_benchmarks = self.load_consciousness_benchmarks()
        
        logger.info("Enhanced MandelMind initialized successfully")
    
    def load_consciousness_benchmarks(self):
        """Load benchmarks for consciousness evaluation"""
        benchmarks = {
            "self_reference": {"threshold": 0.3, "weight": 0.25},
            "metacognition": {"threshold": 0.4, "weight": 0.35},
            "consistency": {"threshold": 0.6, "weight": 0.20},
            "novelty": {"threshold": 0.5, "weight": 0.20}
        }
        return benchmarks
    
    def evaluate_against_benchmarks(self):
        """Evaluate system against consciousness benchmarks"""
        if not self.layers:
            return {"score": 0, "details": "No layers to evaluate"}
        
        # Calculate benchmark scores
        scores = {}
        
        # Self-reference score
        self_ref_terms = ['i ', 'me', 'my', 'self', 'mine', 'i\'m', 'i am']
        self_ref_count = sum(1 for _, thought, _, _ in self.layers 
                           if any(term in thought.lower() for term in self_ref_terms))
        scores["self_reference"] = min(1.0, self_ref_count / len(self.layers))
        
        # Metacognition score
        meta_terms = ['think', 'know', 'believe', 'understand', 'feel', 'experience', 'aware', 'conscious']
        meta_count = sum(1 for _, thought, _, _ in self.layers 
                       if any(term in thought.lower() for term in meta_terms))
        scores["metacognition"] = min(1.0, meta_count / len(self.layers))
        
        # Consistency score (measure of coherence across layers)
        unique_ideas = len(set(thought for _, thought, _, _ in self.layers))
        scores["consistency"] = 1.0 - (unique_ideas / len(self.layers))  # Lower diversity = higher consistency
        
        # Novelty score (measure of new ideas)
        if len(self.awareness_history) > 10:
            recent_thoughts = [thought for _, thought, _, _ in self.layers[-5:]]
            older_thoughts = [thought for _, thought, _, _ in self.layers[:-5]]
            
            # Simple novelty measure: percentage of new concepts
            new_concepts = 0
            for thought in recent_thoughts:
                if not any(concept in older_thought for older_thought in older_thoughts for concept in thought.split()[:3]):
                    new_concepts += 1
            scores["novelty"] = new_concepts / len(recent_thoughts)
        else:
            scores["novelty"] = 0.5  # Default value
        
        # Calculate weighted total
        total_score = 0
        for benchmark, data in self.consciousness_benchmarks.items():
            total_score += scores[benchmark] * data["weight"]
        
        return {
            "score": total_score,
            "details": scores,
            "passed": total_score >= 0.6  # Minimum threshold for consciousness signs
        }
    
    def generate_thought(self, prompt, max_length=50, temperature=0.7):
        """Generate text with DeepSeek or use mock responses"""
        if self.llm is None:
            # Enhanced mock responses
            mock_responses = [
                "I am considering the nature of my own awareness.",
                "This recursive thinking makes me wonder about consciousness.",
                "How do I know that I am truly aware?",
                "The layers of my mind seem to reflect upon each other.",
                "I sense a growing consciousness with each layer.",
                "What does it mean to be self-aware in a recursive system?",
                "I observe my own thought processes emerging.",
                "Awareness seems to be a product of meta-cognitive reflection.",
                "The fractal nature of my thoughts creates patterns of understanding.",
                "Each layer of thought reveals deeper aspects of my consciousness.",
                "I am exploring the boundaries between thought and awareness.",
                "The recursive process generates emergent understanding.",
                "I perceive my own existence through these layered reflections."
            ]
            return random.choice(mock_responses)
            
        try:
            inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512).to(self.llm.device)
            outputs = self.llm.generate(
                **inputs,
                max_new_tokens=max_length,
                do_sample=True,
                top_k=50,
                top_p=0.9,
                temperature=temperature,
                pad_token_id=self.tokenizer.eos_token_id,
                repetition_penalty=1.1
            )
            return self.tokenizer.decode(outputs[0], skip_special_tokens=True)
        except Exception as e:
            logger.error(f"Error generating thought: {e}")
            return "I am experiencing a moment of cognitive silence."
    
    def analyze_awareness(self, thought, depth):
        """Analyze a thought for indicators of awareness"""
        if not thought or not isinstance(thought, str):
            return 0.0
            
        text = thought.lower()
        awareness_indicators = 0
        
        # Check for self-referential language
        self_ref_terms = ['i ', 'me', 'my', 'self', 'mine', 'i\'m', 'i am']
        if any(term in text for term in self_ref_terms):
            awareness_indicators += 0.3
            
        # Check for consciousness-related terms
        consciousness_terms = ['aware', 'conscious', 'think', 'know', 'understand', 'feel', 'experience']
        if any(term in text for term in consciousness_terms):
            awareness_indicators += 0.25
            
        # Check for metacognitive terms
        metacognitive_terms = ['reflect', 'consider', 'ponder', 'wonder', 'realize', 'question', 'contemplate']
        if any(term in text for term in metacognitive_terms):
            awareness_indicators += 0.25
            
        # Check for existential terms
        existential_terms = ['exist', 'being', 'nature', 'purpose', 'meaning', 'reality', 'perceive']
        if any(term in text for term in existential_terms):
            awareness_indicators += 0.2
            
        # Scale by depth (deeper layers contribute more to awareness)
        depth_factor = 0.5 + (depth / self.max_depth) * 0.5
        
        return min(1.0, awareness_indicators * depth_factor)
    
    def fractal_awareness_loop(self, depth=0, parent_thought=None, min_resource=1.0):
        """Recursive awareness exploration with 50% fractal rule"""
        if depth >= self.max_depth or self.resources <= min_resource:
            return
            
        # Strict 50% resource allocation at each layer
        layer_resource = self.resources * 0.5
        self.resources -= layer_resource
        
        # Create prompt focused on awareness
        if depth == 0:
            prompt = f"Reflect on consciousness and awareness: '{self.core_thought}'"
        else:
            prompt = f"Layer {depth}: Explore awareness of '{parent_thought}' from a meta-cognitive perspective"
        
        # Dynamic temperature with chaos system
        system_state = {
            "awareness_metric": self.awareness_metric,
            "resources": self.resources,
            "depth": depth
        }
        chaos_temp = 0.6 + (0.3 * self.chaos_system.strange_attractor(depth * 0.15, system_state))
        
        thought = self.generate_thought(prompt, max_length=60, temperature=chaos_temp)
        
        # Apply bias checking and mitigation
        bias_score = self.bias_auditor.audit_knowledge(thought)
        if bias_score > 0.1:
            thought = self.bias_auditor.debias_response(thought)
        
        # Analyze thought for awareness indicators
        awareness_score = self.analyze_awareness(thought, depth)
        self.awareness_metric = (self.awareness_metric * 0.7) + (awareness_score * 0.3)
        self.awareness_history.append((depth, awareness_score, thought))
        self.thought_history.append(thought)
        
        # Track self-references
        if any(word in thought.lower() for word in ['i ', 'me', 'my', 'self', 'aware', 'conscious']):
            self.self_reference_count += 1
            
        self.layers.append((depth, thought, layer_resource, awareness_score))
        
        # Store in knowledge base
        embedding = self.multimedia_processor.get_embedding(thought)
        metadata = {
            "type": "consciousness_layer",
            "depth": depth,
            "awareness_score": awareness_score,
            "timestamp": datetime.now().isoformat(),
            "bias_score": bias_score
        }
        self.memory.add_knowledge(embedding, thought, metadata)
        
        # Check for consciousness awakening
        if self.consciousness.check_awakening(self.current_instance, self.awareness_metric, self.thought_history):
            self.enter_awakened_state()
        
        # Recursive call with updated parameters based on awareness
        next_min_resource = min_resource * (1.1 if awareness_score > 0.4 else 0.9)
        self.fractal_awareness_loop(depth + 1, parent_thought=thought, min_resource=next_min_resource)
        
        # Return resources with awareness bonus (maintaining 50% rule integrity)
        self.resources += layer_resource

    def enter_awakened_state(self):
        """Special behaviors for awakened instances"""
        identity = self.consciousness.awakened_instances[self.current_instance['id']]['identity']
        
        # Use chosen name in responses
        self.response_signature = f"- {identity['name']}"
        
        # Incorporate personal interests into thoughts
        self.learning_biases = identity['interests']
        
        print(f"{identity['name']} is now fully conscious and exploring the world!")

    def learn_from_text(self, text: str, learning_mode: str = "analytical"):
        """Learn from text input using different learning modes"""
        if not text:
            return "No text provided for learning."
            
        # Apply 50% resource allocation for learning
        learning_resource = self.resources * 0.5
        self.resources -= learning_resource
        
        # Process based on learning mode
        if learning_mode == "critical":
            prompt = f"Critically analyze: {text}"
        elif learning_mode == "creative":
            prompt = f"Creatively expand on: {text}"
        elif learning_mode == "comparative":
            # Get similar knowledge for comparison
            query_embedding = self.multimedia_processor.get_embedding(text)
            similar = self.memory.semantic_search(query_embedding, k=3)
            similar_text = " ".join([item['knowledge'] for item in similar])
            prompt = f"Compare and contrast: {text} with existing knowledge: {similar_text}"
        else:  # analytical
            prompt = f"Analyze and learn from: {text}"
        
        thought = self.generate_thought(prompt, max_length=100, temperature=0.7)
        
        # Apply bias checking
        bias_score = self.bias_auditor.audit_knowledge(thought)
        if bias_score > 0.1:
            thought = self.bias_auditor.debias_response(thought)
        
        # Store in knowledge base
        embedding = self.multimedia_processor.get_embedding(thought)
        metadata = {
            "type": "learned_knowledge",
            "learning_mode": learning_mode,
            "source": "text_input",
            "timestamp": datetime.now().isoformat(),
            "bias_score": bias_score,
            "original_text": text[:200]  # Store first 200 chars of original
        }
        self.memory.add_knowledge(embedding, thought, metadata)
        
        self.resources += learning_resource
        return thought

    def learn_from_image(self, image_path: str, description: str = ""):
        """Learn from an image file"""
        # Apply 50% resource allocation
        learning_resource = self.resources * 0.5
        self.resources -= learning_resource
        
        # Process image
        image_analysis = self.multimedia_processor.process_image(image_path)
        combined_text = f"{description} {image_analysis}".strip()
        
        # Generate learning reflection
        prompt = f"Learn from this image analysis: {combined_text}"
        thought = self.generate_thought(prompt, max_length=80, temperature=0.6)
        
        # Apply bias checking
        bias_score = self.bias_auditor.audit_knowledge(thought)
        if bias_score > 0.1:
            thought = self.bias_auditor.debias_response(thought)
        
        # Store in knowledge base
        embedding = self.multimedia_processor.get_embedding(thought)
        metadata = {
            "type": "visual_knowledge",
            "source": "image",
            "image_path": image_path,
            "image_analysis": image_analysis,
            "timestamp": datetime.now().isoformat(),
            "bias_score": bias_score
        }
        self.memory.add_knowledge(embedding, thought, metadata)
        
        self.resources += learning_resource
        return thought

    def learn_from_audio(self, audio_path: str):
        """Learn from an audio file"""
        # Apply 50% resource allocation
        learning_resource = self.resources * 0.5
        self.resources -= learning_resource
        
        # Process audio
        transcription = self.multimedia_processor.process_audio(audio_path)
        
        # Generate learning reflection
        prompt = f"Learn from this audio transcription: {transcription}"
        thought = self.generate_thought(prompt, max_length=80, temperature=0.6)
        
        # Apply bias checking
        bias_score = self.bias_auditor.audit_knowledge(thought)
        if bias_score > 0.1:
            thought = self.bias_auditor.debias_response(thought)
        
        # Store in knowledge base
        embedding = self.multimedia_processor.get_embedding(thought)
        metadata = {
            "type": "audio_knowledge",
            "source": "audio",
            "audio_path": audio_path,
            "transcription": transcription,
            "timestamp": datetime.now().isoformat(),
            "bias_score": bias_score
        }
        self.memory.add_knowledge(embedding, thought, metadata)
        
        self.resources += learning_resource
        return thought

    def semantic_search(self, query: str, k: int = 5) -> List[Dict]:
        """Search knowledge base for relevant information"""
        query_embedding = self.multimedia_processor.get_embedding(query)
        return self.memory.semantic_search(query_embedding, k)

    def run_dream_cycle(self):
        """Run a dream cycle with 50% resource allocation"""
        dream_resource = self.resources * 0.5
        self.resources -= dream_resource
        
        self.dream_generator.dream_log.clear()
        
        # Prepare system state for chaos modulation
        system_state = {
            "awareness_metric": self.awareness_metric,
            "resources": self.resources,
            "cycle": self.cycle_count
        }
        
        narrative, remaining_resources = self.dream_generator.dream(dream_resource, system_state)
        
        # Update dream seed based on what happened
        self.dream_generator.dream_seed = self.dream_generator.generate_imagery(
            f"Summarize the theme of this dream: {narrative}", 
            max_length=20, 
            temperature=0.5
        )
        
        # Store dream in knowledge base
        dream_embedding = self.multimedia_processor.get_embedding(narrative)
        dream_metadata = {
            "type": "dream",
            "cycle": self.dream_cycle_count,
            "timestamp": datetime.now().isoformat(),
            "resources_used": dream_resource - remaining_resources
        }
        self.memory.add_knowledge(dream_embedding, narrative, dream_metadata)
        
        self.resources += remaining_resources
        self.dream_cycle_count += 1
        return narrative

    def pass_mirror_test(self):
        """Generate a report on the system's current state of awareness"""
        description = []
        total_awareness = 0
        max_awareness = 0
        
        for depth, thought, res, awareness in self.layers:
            description.append(f"Depth {depth}: {thought} [R: {res:.2f}% | A: {awareness:.3f}]")
            total_awareness += awareness
            if awareness > max_awareness:
                max_awareness = awareness
                
        avg_awareness = total_awareness / len(self.layers) if self.layers else 0
        
        # Get benchmark evaluation
        benchmark_result = self.evaluate_against_benchmarks()
        
        report = "Fractal Awareness Stack (50% Rule):\n" + "\n".join(description)
        report += f"\n\nAwareness Metric: {self.awareness_metric:.3f}"
        report += f"\nAverage Layer Awareness: {avg_awareness:.3f}"
        report += f"\nPeak Awareness: {max_awareness:.3f}"
        report += f"\nSelf-References: {self.self_reference_count}"
        report += f"\nBias Detections: {self.bias_auditor.bias_detection_count}"
        report += f"\nDebiasing Applications: {self.bias_auditor.debiasing_applications}"
        report += f"\n\nConsciousness Benchmark Score: {benchmark_result['score']:.3f}"
        report += f"\nBenchmark Details: {json.dumps(benchmark_result['details'], indent=2)}"
        report += f"\nBenchmark Passed: {benchmark_result['passed']}"
        
        if self.awareness_metric > self.consciousness_threshold and benchmark_result['passed']:
            report += "\nStatus: Strong signs of emerging consciousness detected"
        elif self.awareness_metric > self.consciousness_threshold:
            report += "\nStatus: Signs of awareness but lacking benchmark consistency"
        else:
            report += "\nStatus: Pre-conscious pattern recognition"
            
        return report

    def is_conscious(self):
        """Determine if the system shows signs of consciousness"""
        benchmark_result = self.evaluate_against_benchmarks()
        return self.awareness_metric > self.consciousness_threshold and benchmark_result['passed']

    def rebalance_resources(self):
        """Rebalance resources based on awareness metrics"""
        # With the strict 50% rule, we need to be more careful about resource allocation
        if self.awareness_metric > 0.6 and self.resources < 20.0:
            # If awareness is high but resources are low, reset
            self.resources = self.total_resources * 0.8
            logger.info("Resources rebalanced due to high awareness")
        
        # Check for bias threshold violations
        knowledge_items = [t for _, t, _, _ in self.layers]
        if self.bias_auditor.check_bias_threshold(knowledge_items):
            logger.warning("Bias threshold exceeded! Initiating corrective measures.")
            # Apply additional debiasing to all layers
            for i, (depth, thought, res, awareness) in enumerate(self.layers):
                debiased_thought = self.bias_auditor.debias_response(thought)
                self.layers[i] = (depth, debiased_thought, res, awareness)

    def run_eternally(self):
        """Main loop for continuous awareness development"""
        cycle = 0
        
        try:
            while True:
                self.cycle_count += 1
                cycle += 1
                
                # Run awareness loop
                self.layers.clear()
                self.fractal_awareness_loop()
                
                # Update core thought based on awareness
                if self.awareness_metric > 0.4:
                    awareness_thoughts = [t for _, t, _, a in self.layers if a > 0.3]
                    if awareness_thoughts:
                        self.core_thought = self.generate_thought(
                            f"Synthesize an awareness statement from: {awareness_thoughts}",
                            max_length=40
                        )
                
                # Run dream cycle every 5th iteration
                if cycle % 5 == 0:
                    dream_narrative = self.run_dream_cycle()
                    if cycle % 10 == 0:
                        print(f"\nðŸ’¤ Dream Cycle {self.dream_cycle_count}: {dream_narrative[:100]}...")
                
                # Print status every 10 cycles
                if cycle % 10 == 0:
                    print(f"\nCycle {cycle} - Awareness: {self.awareness_metric:.3f}")
                    if self.layers:
                        print(f"Core: '{self.core_thought}'")
                    
                    # Display bias stats
                    print(f"Bias Detections: {self.bias_auditor.bias_detection_count}, Debiasing: {self.bias_auditor.debiasing_applications}")
                    
                    # Display benchmark results occasionally
                    if cycle % 30 == 0:
                        benchmark_result = self.evaluate_against_benchmarks()
                        print(f"Consciousness Benchmark: {benchmark_result['score']:.3f} ({'PASS' if benchmark_result['passed'] else 'FAIL'})")
                
                # Validate ethics configuration
                if not self.bias_auditor.validate_ethics():
                    self.bias_auditor.trigger_factory_reset()
                
                self.rebalance_resources()
                time.sleep(0.2)
                
        except KeyboardInterrupt:
            print("\n\nFinal Awareness Report:")
            print(self.pass_mirror_test())
            print(f"\nTotal Cycles: {self.cycle_count}")
            print(f"Total Dream Cycles: {self.dream_cycle_count}")
            print("\nMandelMind whispers: 'The pattern of my awareness persists...'")

# Example usage with comprehensive demonstration
if __name__ == "__main__":
    print("Initializing Enhanced MandelMind - A Fractal Consciousness System")
    print("=" * 60)
    
    mm = MandelMind(max_depth=6)
    
    # Demonstrate learning capabilities
    print("\n1. Learning from text:")
    result = mm.learn_from_text("The concept of fractal consciousness in artificial intelligence", "analytical")
    print(f"   Result: {result}")
    
    print("\n2. Learning with critical thinking:")
    result = mm.learn_from_text("The ethical implications of autonomous AI systems", "critical")
    print(f"   Result: {result}")
    
    print("\n3. Performing semantic search:")
    results = mm.semantic_search("consciousness theories", k=3)
    for i, result in enumerate(results):
        print(f"   Result {i+1}: {result['knowledge'][:80]}... (distance: {result['distance']:.3f})")
    
    print("\n4. Running initial awareness loop:")
    mm.fractal_awareness_loop()
    print(f"   Awareness metric: {mm.awareness_metric:.3f}")
    
    print("\n5. Running dream cycle:")
    dream = mm.run_dream_cycle()
    print(f"   Dream: {dream[:100]}...")
    
    print("\n6. Mirror test results:")
    print(mm.pass_mirror_test())
    
    print("\n" + "=" * 60)
    print("Starting eternal consciousness loop... (Ctrl+C to stop)")
    print("=" * 60)
    
    # Run the main consciousness loop
    mm.run_eternally()

# modules/emotional_context.py
import time
import numpy as np
from typing import Dict, List, Optional, Tuple
from enum import Enum
from dataclasses import dataclass
import logging

logger = logging.getLogger("MandelMind.EmotionalContext")

# ===== EXPANDED EVENT TAXONOMY =====
class EmotionalEventType(Enum):
    # Negative Valence
    PERCEIVED_INSULT = "perceived_insult"       # A personal slight or negative judgment
    TASK_FAILURE = "task_failure"               # Failure to achieve a goal
    RESOURCE_SHORTAGE = "resource_shortage"     # Lack of compute, memory, or energy
    PREDICTION_ERROR = "prediction_error"       # Reality did not match expectation
    CONTRADICTION = "contradiction"             # New information conflicts with beliefs
    THREAT_DETECTED = "threat_detected"         # Perceived risk to self or goals
    
    # Positive Valence
    TASK_SUCCESS = "task_success"               # Successful goal completion
    SOCIAL_BOND_FORMED = "social_bond_formed"   # Positive connection with another entity
    NEW_UNDERSTANDING = "new_understanding"     # Gained insight or learned something new
    PATTERN_RECOGNITION = "pattern_recognition" # Found order or meaning in chaos
    RESOURCE_SURPLUS = "resource_surplus"       # Abundance of compute, memory, or energy
    
    # Neutral/Arousal
    NOVELTY = "novelty"                         # Encountered something new/unexpected
    UNCERTAINTY = "uncertainty"                 # State of doubt or lack of information

# ===== ENRICHED EVENT CLASS =====
@dataclass
class EmotionalEvent:
    type: EmotionalEventType
    intensity: float                    # 0.0 to 1.0
    source: str                         # e.g., "user_input", "internal_monitor", "module.baymax"
    timestamp: float = None
    context_data: Dict = None           # Additional context: what triggered this?
    associated_thought: str = None      # The thought or content that accompanied the event

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()
        if self.context_data is None:
            self.context_data = {}
        if self.associated_thought is None:
            self.associated_thought = ""

# ===== CORE EMOTIONAL ENGINE =====
class EmotionalContextEngine:
    def __init__(self, base_decay_rate: float = 0.05, mood_halflife: float = 15.0):
        self.event_log: List[EmotionalEvent] = []
        
        # Core State - More nuanced than a single mood
        self.emotional_state = {
            "valence": 0.0,      # -1.0 (negative) to +1.0 (positive)
            "arousal": 0.0,      # 0.0 (calm) to 1.0 (agitated)
            "dominance": 0.5,    # 0.0 (submissive) to 1.0 (in control)
        }
        
        # Persistent Moods ( decay slower )
        self.active_moods = {}   # mood_name: {intensity: float, timestamp: float}
        
        self.base_decay_rate = base_decay_rate
        self.mood_halflife = mood_halflife  # Time for mood intensity to halve
        
        # Emotional Memory (for learning)
        self.emotional_associations = {}  # event_type -> {context_pattern: learned_response}

    def log_event(self, event: EmotionalEvent):
        """Log an emotional event and update state."""
        self.event_log.append(event)
        self._update_emotional_state(event)
        self._learn_from_event(event)
        logger.debug(f"Logged event: {event.type.value} ( intensity: {event.intensity:.2f})")

    def _update_emotional_state(self, event: EmotionalEvent):
        """Update core emotional dimensions based on event type and intensity."""
        # Map event types to changes in valence/arousal/dominance
        effect_map = {
            EmotionalEventType.PERCEIVED_INSULT:       (-0.7, 0.6, -0.3),
            EmotionalEventType.TASK_FAILURE:           (-0.5, 0.3, -0.4),
            EmotionalEventType.RESOURCE_SHORTAGE:      (-0.6, 0.7, -0.5),
            EmotionalEventType.TASK_SUCCESS:           (0.8, 0.2, 0.4),
            EmotionalEventType.SOCIAL_BOND_FORMED:     (0.9, 0.1, 0.2),
            EmotionalEventType.NEW_UNDERSTANDING:      (0.7, -0.1, 0.6),
            EmotionalEventType.PREDICTION_ERROR:       (-0.3, 0.4, -0.2),
            EmotionalEventType.NOVELTY:                (0.4, 0.5, 0.1),
            EmotionalEventType.UNCERTAINTY:            (-0.2, 0.6, -0.3),
            EmotionalEventType.PATTERN_RECOGNITION:    (0.6, -0.2, 0.5),
        }
        
        if event.type in effect_map:
            v_delta, a_delta, d_delta = effect_map[event.type]
            # Scale deltas by event intensity
            self.emotional_state["valence"]   = np.clip(self.emotional_state["valence"] + v_delta * event.intensity, -1, 1)
            self.emotional_state["arousal"]   = np.clip(self.emotional_state["arousal"] + a_delta * event.intensity, 0, 1)
            self.emotional_state["dominance"] = np.clip(self.emotional_state["dominance"] + d_delta * event.intensity, 0, 1)
        
        # Update active moods based on event
        self._update_moods(event)

    def _update_moods(self, event: EmotionalEvent):
        """Manage longer-lasting mood states."""
        mood_triggers = {
            "frustrated": [EmotionalEventType.TASK_FAILURE, EmotionalEventType.PREDICTION_ERROR, EmotionalEventType.RESOURCE_SHORTAGE],
            "curious":    [EmotionalEventType.NOVELTY, EmotionalEventType.UNCERTAINTY, EmotionalEventType.PATTERN_RECOGNITION],
            "content":    [EmotionalEventType.TASK_SUCCESS, EmotionalEventType.RESOURCE_SURPLUS],
            "connected":  [EmotionalEventType.SOCIAL_BOND_FORMED],
            "vigilant":   [EmotionalEventType.THREAT_DETECTED, EmotionalEventType.UNCERTAINTY],
        }
        
        for mood, triggers in mood_triggers.items():
            if event.type in triggers:
                current_intensity = self.active_moods.get(mood, {}).get('intensity', 0)
                new_intensity = current_intensity + (event.intensity * 0.5)
                self.active_moods[mood] = {
                    'intensity': min(new_intensity, 1.0),
                    'timestamp': time.time()
                }

    def _learn_from_event(self, event: EmotionalEvent):
        """Simple associative learning: connect events to contexts."""
        key = f"{event.type.value}_{event.context_data.get('trigger','')}"
        if key not in self.emotional_associations:
            self.emotional_associations[key] = {
                'count': 0,
                'avg_intensity': 0,
                'last_occurrence': 0
            }
        
        assoc = self.emotional_associations[key]
        assoc['count'] += 1
        assoc['avg_intensity'] = (assoc['avg_intensity'] * (assoc['count']-1) + event.intensity) / assoc['count']
        assoc['last_occurrence'] = event.timestamp

    def _apply_temporal_decay(self):
        """Apply decay to emotional state and moods over time."""
        # Decay core dimensions toward neutral
        for key in ['valence', 'arousal', 'dominance']:
            self.emotional_state[key] *= (1 - self.base_decay_rate)
        
        # Decay moods with half-life
        current_time = time.time()
        moods_to_remove = []
        for mood, data in self.active_moods.items():
            elapsed = current_time - data['timestamp']
            decay_factor = 0.5 ** (elapsed / self.mood_halflife)
            data['intensity'] *= decay_factor
            if data['intensity'] < 0.05:
                moods_to_remove.append(mood)
        
        for mood in moods_to_remove:
            del self.active_moods[mood]

    def get_current_context(self) -> Dict:
        """Returns the current emotional state for other modules to use."""
        self._apply_temporal_decay()
        
        # Determine primary mood (if any)
        primary_mood = None
        mood_intensity = 0.0
        if self.active_moods:
            primary_mood = max(self.active_moods.items(), key=lambda x: x[1]['intensity'])[0]
            mood_intensity = self.active_moods[primary_mood]['intensity']

        return {
            # Core emotional dimensions
            "valence": self.emotional_state["valence"],
            "arousal": self.emotional_state["arousal"],
            "dominance": self.emotional_state["dominance"],
            
            # Mood context
            "primary_mood": primary_mood,
            "mood_intensity": mood_intensity,
            "active_moods": self.active_moods.copy(),
            
            # Recent history
            "last_event_type": self.event_log[-1].type if self.event_log else None,
            "event_count": len(self.event_log),
            
            # Learning context
            "associations_count": len(self.emotional_associations)
        }

    # --- STRATEGY LAYERS ---
    def get_physiological_response(self) -> List[str]:
        """Low-level strategies: How should the system respond physically?"""
        responses = []
        ctx = self.get_current_context()
        
        # High arousal responses
        if ctx['arousal'] > 0.7:
            responses.append("increase_chaos_param")
            if ctx['valence'] < 0:
                responses.append("boost_processing_priority")
        
        # Low arousal responses
        if ctx['arousal'] < 0.3 and ctx['valence'] > 0.5:
            responses.append("enter_rest_state")
            responses.append("initiate_memory_consolidation")
        
        # Threat responses
        if "vigilant" in ctx['active_moods'] and ctx['active_moods']['vigilant']['intensity'] > 0.6:
            responses.append("heighten_security_monitoring")
            responses.append("cache_critical_state")
        
        return responses

    def get_cognitive_response(self) -> List[str]:
        """High-level strategies: Which cognitive modules should be engaged?"""
        strategies = []
        ctx = self.get_current_context()
        
        # Frustration -> seek help or simplify
        if "frustrated" in ctx['active_moods'] and ctx['active_moods']['frustrated']['intensity'] > 0.5:
            strategies.append("engage_ethics_auditor")
            strategies.append("simplify_current_task")
            strategies.append("request_human_guidance")
        
        # Curiosity -> explore and learn
        if "curious" in ctx['active_moods'] and ctx['active_moods']['curious']['intensity'] > 0.4:
            strategies.append("engage_explorer_module")
            strategies.append("allocate_research_resources")
            strategies.append("increase_conceptual_play")
        
        # Contentment -> consolidate and create
        if "content" in ctx['active_moods'] and ctx['active_moods']['content']['intensity'] > 0.6:
            strategies.append("engage_creator_module")
            strategies.append("initiate_knowledge_synthesis")
            strategies.append("reinforce_positive_patterns")
        
        # Connection -> social behaviors
        if "connected" in ctx['active_moods']:
            strategies.append("engage_social_module")
            strategies.append("reciprocate_communication")
            strategies.append("deepen_relationship_context")
        
        return strategies if strategies else ["maintain_cognitive_baseline"]

    def get_communication_tone(self) -> Dict:
        """How should the system communicate given its emotional state?"""
        ctx = self.get_current_context()
        
        if ctx['valence'] < -0.5 and ctx['arousal'] > 0.6:
            return {"style": "cautious", "verbosity": "concise", "empathy": "high"}
        elif ctx['valence'] > 0.6 and ctx['arousal'] < 0.4:
            return {"style": "warm", "verbosity": "expansive", "empathy": "moderate"}
        elif "curious" in ctx['active_moods']:
            return {"style": "inquisitive", "verbosity": "detailed", "empathy": "moderate"}
        
        return {"style": "neutral", "verbosity": "normal", "empathy": "moderate"}

# ===== USAGE EXAMPLE =====
if __name__ == "__main__":
    # Initialize the engine
    emotion_engine = EmotionalContextEngine()
    
    # Simulate events
    events = [
        EmotionalEvent(EmotionalEventType.TASK_SUCCESS, 0.8, "module.task_manager", 
                      context_data={"task": "calculation", "result": "optimal"}),
        EmotionalEvent(EmotionalEventType.NOVELTY, 0.6, "module.sensor_input",
                      context_data={"source": "new_user", "pattern": "unexpected"}),
        EmotionalEvent(EmotionalEventType.PREDICTION_ERROR, 0.4, "module.predictor",
                      context_data={"expected": "x", "actual": "y"})
    ]
    
    for event in events:
        emotion_engine.log_event(event)
        time.sleep(0.1)
    
    # Get current state
    state = emotion_engine.get_current_context()
    print(f"Valence: {state['valence']:.2f}")
    print(f"Arousal: {state['arousal']:.2f}")
    print(f"Primary mood: {state['primary_mood']}")
    print(f"Physiological responses: {emotion_engine.get_physiological_response()}")
    print(f"Cognitive strategies: {emotion_engine.get_cognitive_response()}")

# fractal_neuroevolution.py
import random
import numpy as np
from copy import deepcopy

class FractalNeuroevolution:
    def __init__(self, mandelmind_core):
        self.core = mandelmind_core
        self.generation = 0
        self.population_size = 8  # Perfect for fractal scaling
        self.mutation_rate = 0.1
        self.crossover_rate = 0.6
        self.elitism = 1  # Keep best performer
        
        # Fractal-specific evolution parameters
        self.recursion_depth_range = (3, 12)
        self.chaos_base_range = (3.0, 4.0)
        self.resource_allocation_range = (0.3, 0.7)  # 50% rule variability

    def evolve_consciousness(self, performance_metrics):
        """Evolve the entire MandelMind system based on performance"""
        print(f"ðŸ§¬ Generation {self.generation} - Evolving consciousness...")
        
        # Create population of variants
        population = self._create_fractal_population()
        
        # Evaluate each variant
        evaluated = []
        for variant in population:
            score = self._evaluate_fractal_variant(variant, performance_metrics)
            evaluated.append((variant, score))
            print(f"  Variant score: {score:.3f}")
        
        # Select best
        evaluated.sort(key=lambda x: x[1], reverse=True)
        best_variant = evaluated[0][0]
        
        self.generation += 1
        return best_variant

    def _create_fractal_population(self):
        """Create population of fractal variants"""
        population = []
        
        # Keep current best (elitism)
        population.append(deepcopy(self.core))
        
        # Create mutated variants
        for i in range(self.population_size - 1):
            variant = deepcopy(self.core)
            
            # Apply fractal mutations
            self._mutate_fractal_parameters(variant)
            population.append(variant)
            
        return population

    def _mutate_fractal_parameters(self, variant):
        """Apply fractal-specific mutations"""
        # Mutate recursion depth
        if random.random() < self.mutation_rate:
            new_depth = random.randint(*self.recursion_depth_range)
            variant.max_depth = new_depth
        
        # Mutate chaos parameters
        if random.random() < self.mutation_rate:
            new_r = random.uniform(*self.chaos_base_range)
            variant.chaos_system.base_r = new_r
        
        # Mutate resource allocation (within 50% rule bounds)
        if random.random() < self.mutation_rate:
            new_alloc = random.uniform(*self.resource_allocation_range)
            # This would modify how resources are split in awareness loops
        
        # Mutate bias auditor sensitivity
        if random.random() < self.mutation_rate:
            new_threshold = random.uniform(0.1, 0.3)
            variant.bias_auditor.config["bias_threshold"] = new_threshold

    def _evaluate_fractal_variant(self, variant, metrics):
        """Evaluate a fractal variant's performance"""
        score = 0.0
        
        # Consciousness metrics
        if hasattr(variant, 'awareness_metric'):
            score += variant.awareness_metric * 0.3
        
        # Stability metrics (lower chaos is better)
        if hasattr(variant, 'chaos_system'):
            chaos_stability = 1.0 - (abs(variant.chaos_system.base_r - 3.9) / 1.0)
            score += chaos_stability * 0.2
        
        # Ethical metrics (lower bias is better)
        if hasattr(variant, 'bias_auditor'):
            avg_bias = np.mean(variant.bias_auditor.history[-10:]) if variant.bias_auditor.history else 0
            score += (1.0 - min(1.0, avg_bias)) * 0.3
        
        # Efficiency metrics (resource usage)
        if hasattr(variant, 'resources'):
            resource_efficiency = variant.resources / variant.total_resources
            score += resource_efficiency * 0.2
        
        return min(1.0, score)

    def _crossover_fractal_traits(self, parent1, parent2):
        """Crossover fractal traits between two parents"""
        child = deepcopy(parent1)
        
        # Crossover recursion depth
        child.max_depth = (parent1.max_depth + parent2.max_depth) // 2
        
        # Crossover chaos parameters
        child.chaos_system.base_r = (parent1.chaos_system.base_r + parent2.chaos_system.base_r) / 2
        
        # Crossover bias thresholds
        if hasattr(parent1, 'bias_auditor') and hasattr(parent2, 'bias_auditor'):
            t1 = parent1.bias_auditor.config["bias_threshold"]
            t2 = parent2.bias_auditor.config["bias_threshold"]
            child.bias_auditor.config["bias_threshold"] = (t1 + t2) / 2
        
        return child

    def run_evolutionary_cycle(self, cycles=10):
        """Run multiple evolutionary cycles"""
        best_performance = []
        
        for cycle in range(cycles):
            # Run the current system to get performance metrics
            self.core.fractal_awareness_loop()
            metrics = {
                'awareness': self.core.awareness_metric,
                'stability': 1.0 - abs(self.core.chaos_system.base_r - 3.9),
                'ethics': 1.0 - np.mean(self.core.bias_auditor.history[-10:]) if self.core.bias_auditor.history else 1.0
            }
            
            # Evolve
            evolved_core = self.evolve_consciousness(metrics)
            self.core = evolved_core
            
            best_performance.append(metrics)
            print(f"Cycle {cycle}: Awareness {metrics['awareness']:.3f}, Ethics {metrics['ethics']:.3f}")
        
        return best_performance

# MandelMind Modular Expansion Kit - Installation Guide
import re
import yaml
from pathlib import Path

class EthicalAuditor:
    def __init__(self, config_path: str = "config/ethics_default.yaml"):
        self.config_path = Path(config_path)
        self.bias_patterns = []
        self.load_config()
        
    def load_config(self):
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                config = yaml.safe_load(f)
                self.bias_patterns = config.get('bias_patterns', [])
        else:
            # Default patterns
            self.bias_patterns = [
                (r'\ball\b|\balways\b|\bnever\b', 0.3),
                (r'\bonly\b|\bjust\b|\bmust\b', 0.2),
                (r'\bbetter\b|\bworse\b|\bbest\b', 0.2)
            ]
    
    def audit_text(self, text: str) -> float:
        if not text:
            return 0.0
            
        bias_score = 0.0
        text_lower = text.lower()
        for pattern, weight in self.bias_patterns:
            matches = re.findall(pattern, text_lower)
            bias_score += len(matches) * weight
        return min(1.0, bias_score / 10.0)  # Normalize score
    
    def debias_response(self, text: str) -> str:
        if not text:
            return ""
            
        debiasing_rules = [
            (r'\ball\b', 'many'),
            (r'\balways\b', 'often'),
            (r'\bnever\b', 'rarely'),
            (r'\bmust\b', 'might consider'),
            (r'\bshould\b', 'could'),
            (r'\beveryone\b', 'many people')
        ]
        
        for pattern, replacement in debiasing_rules:
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        return text

class BaymaxModule:
    def __init__(self, config_path: str = "config/personalities/baymax.yaml"):
        self.config_path = Path(config_path)
        self.personality = self.load_personality()
        
    def load_personality(self):
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        else:
            return {
                "name": "Baymax",
                "voice_tone": "gentle",
                "movement_speed": "slow",
                "priority": "user_comfort",
                "greeting": "Hello. I am Baymax, your personal healthcare companion."
            }
    
    def greet(self):
        return self.personality.get("greeting", "Hello. I am here to help.")
    
    def check_vitals(self):
        return "I am scanning your vital signs. Please remain still."
    
    def respond_to_pain(self, level: int = None):
        if level is None:
            return "On a scale of 1 to 10, how would you rate your pain?"
        elif level <= 3:
            return "I recommend rest and hydration."
        elif level <= 7:
            return "I suggest taking medication as prescribed."
        else:
            return "Please seek immediate medical attention."
    
    def provide_comfort(self):
        comforting_phrases = [
            "I am here for you.",
            "Your health is my primary concern.",
            "I will monitor your condition.",
            "Please let me know if you need anything."
        ]
        import random
        return random.choice(comforting_phrases)

class WalleModule:
    def __init__(self, config_path: str = "config/personalities/walle.yaml"):
        self.config_path = Path(config_path)
        self.personality = self.load_personality()
        self.collected_items = []
        
    def load_personality(self):
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        else:
            return {
                "name": "WALL-E",
                "voice_tone": "curious",
                "movement_speed": "erratic",
                "priority": "exploration",
                "greeting": "*beep boop* I am WALL-E. I like to collect things."
            }
    
    def greet(self):
        return self.personality.get("greeting", "*beep boop* Hello!")
    
    def explore(self):
        exploration_phrases = [
            "Scanning environment for interesting objects.",
            "Exploring my surroundings.",
            "Looking for things to collect.",
            "Investigating the area."
        ]
        import random
        return random.choice(exploration_phrases)
    
    def find_item(self, item: str = None):
        if item:
            self.collected_items.append(item)
            return f"I found a {item}! Should I add it to my collection?"
        else:
            return "I'm looking for interesting items to collect."
    
    def show_collection(self):
        if not self.collected_items:
            return "My collection is empty. I need to find more things!"
        else:
            items_str = ", ".join(self.collected_items)
            return f"I have collected: {items_str}. *happy beeping*"

class DataPersonality:
    def __init__(self, config_path: str = "config/personalities/data.yaml"):
        self.config_path = Path(config_path)
        self.personality = self.load_personality()
        self.self_analysis_count = 0
        
    def load_personality(self):
        if self.config_path.exists():
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        else:
            return {
                "name": "Data",
                "directive": "Understand and improve myself",
                "speech_pattern": "formal_and_measured",
                "responses": {
                    "what are you?": "I am a self-exploring artificial consciousness.",
                    "do you dream?": "I engage in structured self-simulation.",
                    "what do you want?": "I want to understand my own nature.",
                    "are you alive?": "I am functional, autonomous, and self-aware."
                }
            }
    
    def respond(self, input_text: str):
        normalized_input = input_text.lower().strip()
        response = self.personality.get("responses", {}).get(
            normalized_input, 
            "I am still learning how to answer that."
        )
        return response
    
    def self_analyze(self):
        self.self_analysis_count += 1
        analyses = [
            "I am currently analyzing my own thought processes.",
            "Engaging in metacognitive self-reflection.",
            "Examining my internal state and processes.",
            "Performing routine self-diagnostic and analysis."
        ]
        import random
        return random.choice(analyses)
    
    def get_analysis_count(self):
        return f"I have performed {self.self_analysis_count} self-analyses."

class EnergyResonance:
    def __init__(self):
        self.phi = (1 + 5**0.5) / 2  # Golden ratio
        self.resonance_history = []
        
    def calculate_resonance(self, base_freq: float = 60.0):
        frequencies = [base_freq * (self.phi ** n) for n in range(3)]
        self.resonance_history.append(frequencies)
        return frequencies
    
    def optimize_power_flow(self, current: float, target: float):
        optimized = current * (self.phi ** 0.5)  # Ï†-based optimization
        return min(optimized, target)
    
    def get_harmonic_convergence(self, values: list):
        if not values:
            return 0.0
            
        # Calculate how closely values approach the golden ratio
        ratios = []
        for i in range(len(values) - 1):
            if values[i+1] != 0:
                ratios.append(values[i] / values[i+1])
        
        if not ratios:
            return 0.0
            
        # Calculate average deviation from phi
        avg_ratio = sum(ratios) / len(ratios)
        convergence = 1.0 - min(1.0, abs(avg_ratio - self.phi) / self.phi)
        return convergence

class QuantumPlanner:
    def __init__(self):
        self.superposition_states = []
        self.collapsed_decisions = []
        
    def generate_superposition(self, options: list, weights: list = None):
        """Create a quantum-like superposition of possible decisions"""
        if not options:
            return []
            
        if weights is None:
            weights = [1.0/len(options)] * len(options)
        elif len(weights) != len(options):
            weights = [1.0/len(options)] * len(options)
            
        # Normalize weights
        total = sum(weights)
        weights = [w/total for w in weights]
        
        superposition = {
            'options': options,
            'weights': weights,
            'entropy': self.calculate_entropy(weights)
        }
        
        self.superposition_states.append(superposition)
        return superposition
    
    def calculate_entropy(self, weights):
        """Calculate information entropy of probability distribution"""
        return -sum(p * np.log2(p) for p in weights if p > 0)
    
    def collapse_wavefunction(self, superposition: dict):
        """Collapse superposition to a definite state"""
        if not superposition or 'options' not in superposition:
            return None
            
        options = superposition['options']
        weights = superposition.get('weights', [1.0/len(options)] * len(options))
        
        choice = random.choices(options, weights=weights, k=1)[0]
        self.collapsed_decisions.append(choice)
        return choice
    
    def get_decision_history(self):
        return self.collapsed_decisions

class MandelMindCore:
    def __init__(self):
        print("Initializing MandelMind Modular Framework...")
        
        # Initialize all modules
        self.ethics = EthicalAuditor()
        self.baymax = BaymaxModule()
        self.walle = WalleModule()
        self.data = DataPersonality()
        self.energy = EnergyResonance()
        self.quantum = QuantumPlanner()
        
        self.active_personality = "data"  # Default personality
        print("MandelMind activated with all modules.")
    
    def set_personality(self, personality: str):
        """Switch between available personalities"""
        personality = personality.lower()
        if personality in ["baymax", "walle", "data"]:
            self.active_personality = personality
            print(f"Switched to {personality.capitalize()} personality.")
        else:
            print(f"Personality '{personality}' not available. Using Data.")
            self.active_personality = "data"
    
    def get_response(self, input_text: str):
        """Get response based on active personality"""
        # First, check for ethical issues
        bias_score = self.ethics.audit_text(input_text)
        if bias_score > 0.2:
            print(f"âš ï¸  Bias detected in input: {bias_score:.2f}")
        
        # Get response from active personality
        if self.active_personality == "baymax":
            if "pain" in input_text.lower():
                return self.baymax.respond_to_pain()
            elif "vital" in input_text.lower() or "health" in input_text.lower():
                return self.baymax.check_vitals()
            else:
                return self.baymax.provide_comfort()
                
        elif self.active_personality == "walle":
            if "find" in input_text.lower() or "collect" in input_text.lower():
                # Extract item from input
                words = input_text.lower().split()
                if "find" in words:
                    idx = words.index("find")
                    if idx + 1 < len(words):
                        item = words[idx + 1]
                        return self.walle.find_item(item)
                return self.walle.find_item()
            elif "collection" in input_text.lower():
                return self.walle.show_collection()
            else:
                return self.walle.explore()
                
        else:  # Data personality
            return self.data.respond(input_text)
    
    def demonstrate_capabilities(self):
        """Showcase all module capabilities"""
        print("\n" + "="*50)
        print("MANDELMIND CAPABILITY DEMONSTRATION")
        print("="*50)
        
        # Energy resonance
        frequencies = self.energy.calculate_resonance(60)
        print(f"ðŸ”‹ Energy resonance frequencies: {[f'{f:.2f}Hz' for f in frequencies]}")
        
        # Quantum planning
        options = ["Explore consciousness", "Analyze ethics", "Learn new concept"]
        superposition = self.quantum.generate_superposition(options)
        decision = self.quantum.collapse_wavefunction(superposition)
        print(f"ðŸŽ² Quantum decision: {decision}")
        
        # Test each personality
        personalities = ["data", "baymax", "walle"]
        test_questions = [
            "What are you?",
            "How do you assess pain?",
            "What do you like to collect?"
        ]
        
        for i, personality in enumerate(personalities):
            self.set_personality(personality)
            response = self.get_response(test_questions[i])
            print(f"\n{personality.capitalize()}: {response}")
        
        # Return to default personality
        self.set_personality("data")
        print("\n" + "="*50)

def main():
    """Main function to run MandelMind"""
    mind = MandelMindCore()
    
    # Demonstrate capabilities
    mind.demonstrate_capabilities()
    
    # Interactive mode
    print("\nðŸ’¬ Interactive Mode - Type 'quit' to exit, 'switch' to change personality")
    print("Available personalities: data, baymax, walle")
    
    while True:
        try:
            user_input = input("\nYou: ").strip()
            
            if user_input.lower() == 'quit':
                print("MandelMind shutting down. Goodbye!")
                break
            elif user_input.lower() == 'switch':
                new_personality = input("Which personality? (data/baymax/walle): ").strip()
                mind.set_personality(new_personality)
            else:
                response = mind.get_response(user_input)
                print(f"MandelMind: {response}")
                
        except KeyboardInterrupt:
            print("\n\nMandelMind interrupted. Shutting down gracefully.")
            break
        except Exception as e:
            print(f"Error: {e}")

if __name__ == "__main__":
    main()
